import sys
import scipy
import numpy
import matplotlib
import pandas
import sklearn

##Loading Libraries
import pandas 
from pandas.plotting import scatter_matrix
import matplotlib.pyplot as plt
from sklearn import model_selection
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC

##Import Data from UCI repo using pandas
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"
##Columns from the dataset
names = ['sepal-length','sepal-width','petal-length','petal-width','class']
##Loading the dataset using pandas
dataset = pandas.read_csv(url,names=names);

##printing rows and columns of the dataset
print(dataset.shape)

##prinitng first 30 instances of the dataset
print(dataset.head(30))

##printing mean, mode and other percentiles
print(dataset.describe())

##prinitng size of each class
print(dataset.groupby('class').size())

##plotting uni-varied graphs for understanding each attribute
dataset.plot(kind="box", subplots=True, layout=(2,2), sharex=False, sharey=False)
plt.show()

##plotting a histogram
dataset.hist()
plt.show()

##Multi-varied plot to see the interaction between the different variables
scatter_matrix(dataset)
plt.show()  ##This plot shows High Co-relation and predictability

##Creating a validation dataset
array = dataset.values
X = array[:,0:4] ##This brings the columns from starting till the end
Y = array[:,4] ##This is the class for the output, so we're just grabbing the last column in the dataset
validation_size = 0.20 ##This means that 20% of the data would be held back as our validation dataset
seed = 6 ##From where the numbers would start in generating random numbers
X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X,Y,test_size=validation_size,random_state=seed)

##creating test harness
##for this we'll be using ten-fold cross validation to check the acuuracy
seed = 6
scoring = 'accuracy' ##ratio of correctly predicted instances divided by the total number of instances in the dataset




